
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>05 - From table arrangements to powerful tools - part 2 &#8212; Maths for Biologists</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="06 - Analysing change, continuously" href="../lecture06/06_Analysing_change_continuously.html" />
    <link rel="prev" title="04 - From table arrangements to powerful tools" href="../lecture04/04_From_table_arrangements_to_powerful_tools.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Maths for Biologists</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Maths for Biologists
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture01/01_Making_mathematical_statements.html">
   01 - Making mathematical statements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture02/02_Describing_shapes_and_patterns.html">
   02   - Describing shapes and patterns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture03/03_Analysing_change%2C_one_step_at_a_time.html">
   03   - Analysing change, one step at a time
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture04/04_From_table_arrangements_to_powerful_tools.html">
   04 - From table arrangements to powerful tools
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   05 - From table arrangements to powerful tools - part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture06/06_Analysing_change_continuously.html">
   06 - Analysing change, continuously
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture07/07_Analysing_change_continuously_part2.html">
   07 - Analysing change, continuously (Part 2)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lecture08/08_Calculating_accumulated_change.html">
   08 - Calculating accumulated change
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/lecture01/Tutorial_01.html">
   Tutorial 01
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/lecture02/Tutorial_02.html">
   Tutorial 02
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/lecture05/Tutorial_05.html">
   Tutorial 05
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/lecture06/Tutorial_06.html">
   Tutorial 06
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lecture05/05_From_table_arrangements_to_powerful_tools_part2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/lecture05/05_From_table_arrangements_to_powerful_tools_part2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-transformations">
   Linear transformations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">
   Eigenvalues and eigenvectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-decomposition">
   Vector decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#structured-models-revisited">
   Structured models revisited
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>05 - From table arrangements to powerful tools - part 2</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-transformations">
   Linear transformations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">
   Eigenvalues and eigenvectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vector-decomposition">
   Vector decomposition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#structured-models-revisited">
   Structured models revisited
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="from-table-arrangements-to-powerful-tools-part-2">
<h1>05 - From table arrangements to powerful tools - part 2<a class="headerlink" href="#from-table-arrangements-to-powerful-tools-part-2" title="Permalink to this headline">¶</a></h1>
<div class="section" id="linear-transformations">
<h2>Linear transformations<a class="headerlink" href="#linear-transformations" title="Permalink to this headline">¶</a></h2>
<p>In general terms, a given matrix <span class="math notranslate nohighlight">\(A\)</span> is a representation of what we call a <em>linear transformation</em>, a function from a special kind of set called <em>vector space</em> into another vector space. Vector spaces are generalised sets with particular properties, but for the moment you can think of two-dimensional and three-dimensional cartesian spaces as usual vector spaces. Then vectors are gonna be represented as arrays of real numbers as before: <span class="math notranslate nohighlight">\(\mathbf{n_{0}} = \begin{pmatrix} 7.6  \\ 2.2  \end{pmatrix}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{v} = \begin{pmatrix} x \\ y \\ z \end{pmatrix}\)</span>.</p>
<p>Back to linear transformations, they are usually denoted as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
A:V &amp;\longrightarrow W \\
  \mathbf{v} &amp;\rightarrow A(\mathbf{v}) \end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(W\)</span> are the domain and codomain vector spaces, and the transformation <span class="math notranslate nohighlight">\(A\)</span> is a function that projects vectors <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> into the images <span class="math notranslate nohighlight">\(A(\mathbf{v})\)</span>. The property that defines linear transformations is the following:</p>
<div class="math notranslate nohighlight">
\[A(a\mathbf{v}+b\mathbf{w})=aA(\mathbf{v})+bA(\mathbf{w}),\]</div>
<p>where <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are constants. In other words,for a linear transformation, the image of the transformation <span class="math notranslate nohighlight">\(A\)</span> of a linear combination of two vectors (<span class="math notranslate nohighlight">\(\mathbf{v}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>) is equal to the linear combination of the images of this vectors by <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>If we represent vectors with their components in a cartesian system, the images of the transformation <span class="math notranslate nohighlight">\(A\)</span> will be given be the multiplication of the matrix representation of <span class="math notranslate nohighlight">\(A\)</span> on the vectors.</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Given the matrix <span class="math notranslate nohighlight">\(A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\)</span> and the vectors <span class="math notranslate nohighlight">\(\mathbf{v_1} = \begin{pmatrix} 3  \\ -1  \end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{v_2} = \begin{pmatrix} 2  \\ 3  \end{pmatrix}\)</span>, then we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align} A\mathbf{v_1} &amp;= \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\begin{pmatrix} 3  \\ -1  \end{pmatrix} = \begin{pmatrix} 1  \\ 7  \end{pmatrix} \\  
  A\mathbf{v_2} &amp;= \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\begin{pmatrix} 2  \\ 3  \end{pmatrix} = \begin{pmatrix} 8  \\ 12  \end{pmatrix} = 4\begin{pmatrix} 2  \\ 3  \end{pmatrix} \end{align}\end{split}\]</div>
<p>The vectors and their respective transformations are given by:</p>
<img alt="../_images/lin_trans.png" src="../_images/lin_trans.png" />
<p>We see that under the transformation <span class="math notranslate nohighlight">\(A\)</span>, vector <span class="math notranslate nohighlight">\(\mathbf{v_1}\)</span> gets rotated (counterclockwise) and stretched, while vector <span class="math notranslate nohighlight">\(\mathbf{v_2}\)</span> only gets stretched without changing the direction.</p>
</div>
</div>
<div class="section" id="eigenvalues-and-eigenvectors">
<h2>Eigenvalues and eigenvectors<a class="headerlink" href="#eigenvalues-and-eigenvectors" title="Permalink to this headline">¶</a></h2>
<p>As seen on the previous example, there might be some vectors that upon application of <span class="math notranslate nohighlight">\(A\)</span> do not have their direction changed, only their magnitude (or <em>module</em> of the vector). For these vectors, we have, in general:</p>
<div class="math notranslate nohighlight">
\[A\mathbf{v} = \lambda\mathbf{v}, \quad \mbox{for some constant }\ \lambda\]</div>
<p>But this is equivalent to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
A\mathbf{v} - \lambda\mathbf{v} = 0 \\  
A\mathbf{v} - \lambda I\mathbf{v} = 0 \\
\left(A - \lambda I \right)\mathbf{v} = 0 \end{align},\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(I\)</span> is the identity matrix. The equation <span class="math notranslate nohighlight">\(\left(A - \lambda I \right)\mathbf{v} = 0\)</span> defines a system of linear equations where <span class="math notranslate nohighlight">\(A - \lambda I\)</span> is the coefficient matrix, <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> is the vector of variables, and <span class="math notranslate nohighlight">\(\mathbf{b}=0\)</span>. See that since <span class="math notranslate nohighlight">\(\mathbf{b}=0\)</span> we already know one possible solution for this system, which is <span class="math notranslate nohighlight">\(\mathbf{v}=0\)</span> (all the variables equal to <span class="math notranslate nohighlight">\(0\)</span>). Therefore, either this system has an unique solution (the null solution) or it has infinite solutions, but definitely it is not inconsistent.  Thus, if we want to know all possible non-zero vectors <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> that satisfy <span class="math notranslate nohighlight">\(A\mathbf{v} = \lambda\mathbf{v}\)</span>, we have to impose that the system assumes infinite solutions. This criterium should be defined by the determinant of the matrix of coefficients, as:</p>
<div class="math notranslate nohighlight">
\[\mbox{det}(A-\lambda I) = 0.\]</div>
<p>The determinant then defines a polynomial in the variable <span class="math notranslate nohighlight">\(\lambda\)</span>, <span class="math notranslate nohighlight">\(\mbox{det}(A-\lambda I)=p(\lambda)\)</span>, called <em>characteristic polynomial</em>. Since we are interested in the condition <span class="math notranslate nohighlight">\(p(\lambda)=0\)</span>, what we want to know are the roots <span class="math notranslate nohighlight">\(\lambda\)</span> of this polynomial.</p>
<p>The solutions <span class="math notranslate nohighlight">\(\lambda\)</span> for these equations are called <strong>eigenvalues</strong> and their corresponding vectors are <strong>eigenvectors</strong>. In summary, the eigenvectors are all the vectors that, upon application of <span class="math notranslate nohighlight">\(A\)</span>, remain on the same direction, only changing magnitude, with the eigenvalue being the stretching/compressing factor.</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Let us calculate the eigenvalues and eigenvectors of <span class="math notranslate nohighlight">\(A = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\)</span>. First we need to obtain matrix <span class="math notranslate nohighlight">\((A-\lambda I)\)</span> and to calculate its determinant. We have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}A-\lambda I = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix} - \lambda \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix} = \begin{pmatrix} 1 -\lambda &amp; 2 \\ 3 &amp; 2 -\lambda  \end{pmatrix}\end{split}\]</div>
<p>The characteristic polynomial will be given by <span class="math notranslate nohighlight">\(p(\lambda)=\mbox{det}(A-\lambda I)\)</span>, and applying the rule for the calculus of determinants of matrices size 2, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\lambda)=\mbox{det}(A-\lambda I) = \mbox{det}\begin{pmatrix} 1 -\lambda &amp; 2 \\ 3 &amp; 2 -\lambda  \end{pmatrix} = (1 -\lambda)(2 -\lambda) - 3\cdot 2 \end{split}\]</div>
<div class="math notranslate nohighlight">
\[p(\lambda) = 2 -\lambda -2\lambda +\lambda^2 - 6 = \lambda^2 - 3\lambda -4.\]</div>
<p>Thus, calculating the roots of this 2nd-degree polynomial, we find <span class="math notranslate nohighlight">\(\lambda_1=-1\)</span> and <span class="math notranslate nohighlight">\(\lambda_2=4\)</span>. For each of the eigenvalues, to obtain the eigenvectors we have to solve the linear system  <span class="math notranslate nohighlight">\(A\mathbf{v} = \lambda\mathbf{v}\)</span> for some general vector <span class="math notranslate nohighlight">\(\mathbf{v} = \begin{pmatrix} x  \\ y  \end{pmatrix}\)</span> (with coordinates <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> to be specified). Thus:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_1 = -1}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= -1\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{x + 2y = -x \\ 3x + 2y = -y} \longrightarrow \cases{2x + 2y = 0 \\ 3x + 3y = 0}
\end{align}\)</span></p>
<p>Note that both equations correspond to the same linear equation <span class="math notranslate nohighlight">\(x + y = 0\)</span>, which is exactly what we would expect since we built the system to be underdetermined when we did <span class="math notranslate nohighlight">\(\mbox{det}(A-\lambda I) = 0\)</span>. The eigenvector corresponding to <span class="math notranslate nohighlight">\(\lambda_1\)</span> will be such that <span class="math notranslate nohighlight">\(x + y = 0\)</span> or <span class="math notranslate nohighlight">\(x = -y\)</span>. Thus, we can choose <span class="math notranslate nohighlight">\(\mathbf{v_1} = \begin{pmatrix} 1  \\ -1  \end{pmatrix}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Remember that infinite solutions are possible for the same system. The important is that the condition <span class="math notranslate nohighlight">\(x = -y\)</span> holds. In fact, multiplying a non-zero constant for the vector <span class="math notranslate nohighlight">\(\begin{pmatrix} 1  \\ -1  \end{pmatrix}\)</span> would still give a vector in the same direction. So if <span class="math notranslate nohighlight">\(\mathbf{v_1}\)</span> is an eigenvector, <span class="math notranslate nohighlight">\(k\mathbf{v_1}\ (k \in {\rm I\!R})\)</span> also is.</p>
</div>
  <br />  
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_1 = 4}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 2 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= 4\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{x + 2y = 4x \\ 3x + 2y = 4y} \longrightarrow \cases{-3x + 2y = 0 \\ 3x - 2y = 0}
\end{align}\)</span></p>
<p>Since the eigenvector needs to satisfy <span class="math notranslate nohighlight">\(3x=2y\)</span>, we choose <span class="math notranslate nohighlight">\(\mathbf{v_2} = \begin{pmatrix} 2/3  \\ 1  \end{pmatrix}\)</span>.</p>
<p>The representation of these vectors on the cartesian plane will be:</p>
</li>
</ul>
<img alt="../_images/eigenvec_01.png" src="../_images/eigenvec_01.png" />
</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Let us calculate the eigenvalues and eigenvectors of matrix <span class="math notranslate nohighlight">\(A = \begin{pmatrix} -2 &amp; 1 \\ 0 &amp; -1 \end{pmatrix}\)</span>. We have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\lambda)=\mbox{det}(A-\lambda I) = \mbox{det}\begin{pmatrix} -2 -\lambda &amp; 1 \\ 0 &amp; -1 -\lambda  \end{pmatrix} = (-2 -\lambda)(-1 -\lambda) - 1\cdot 0 \end{split}\]</div>
<div class="math notranslate nohighlight">
\[p(\lambda)=(-2 -\lambda)(-1 -\lambda)\]</div>
<p>Since we need <span class="math notranslate nohighlight">\(p(\lambda)=0\)</span> either one of the two factors has to be zero. So, <span class="math notranslate nohighlight">\(\lambda_1=-2\)</span> and <span class="math notranslate nohighlight">\(\lambda_2=-1\)</span>.<br />
For the eigenvectors:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_1 = -2}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} -2 &amp; 1 \\ 0 &amp; -1 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= -2\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{-2x + y = -2x \\ -y = -2y} \longrightarrow \cases{y = 0 \\ y = 0}
\end{align}\)</span></p>
<p>Since <span class="math notranslate nohighlight">\(y=0\)</span>, we choose <span class="math notranslate nohighlight">\(\mathbf{v_1} = \begin{pmatrix} 1  \\ 0  \end{pmatrix}\)</span>.</p>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_2 = -1}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} -2 &amp; 1 \\ 0 &amp; -1 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= -1\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{-2x + y = -x \\ -y = -y} \longrightarrow \cases{-x + y = 0 \\ y = y}
\end{align}\)</span></p>
<p>The second equation is trivial and provides no information. From the first equation, since <span class="math notranslate nohighlight">\(x=y\)</span>, we choose <span class="math notranslate nohighlight">\(\mathbf{v_2} = \begin{pmatrix} 1  \\ 1  \end{pmatrix}\)</span>.</p>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Note that the two eigenvalues <span class="math notranslate nohighlight">\(\lambda_1 = -2\)</span> and <span class="math notranslate nohighlight">\(\lambda_2 = -1\)</span> correspond to the elements of the main diagonal of the matrix <span class="math notranslate nohighlight">\(A\)</span>. Whenever the matrix <span class="math notranslate nohighlight">\(A\)</span> is <em>triangular</em>, meaning all the elements <em>below</em> the main diagonal are <span class="math notranslate nohighlight">\(0\)</span>, the eigenvalues will correspond to the elements of the main diagonal.</p>
</div>
</div>
</div>
<div class="section" id="vector-decomposition">
<h2>Vector decomposition<a class="headerlink" href="#vector-decomposition" title="Permalink to this headline">¶</a></h2>
<p>Now suppose matrix <span class="math notranslate nohighlight">\(A\)</span> has eigenvalues <span class="math notranslate nohighlight">\(\lambda_1\)</span> and <span class="math notranslate nohighlight">\(\lambda_2\)</span>, with corresponding eigenvectors <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span>. If <span class="math notranslate nohighlight">\(\lambda_1 \ne \lambda_2\)</span>, then the vectors <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span> are <em>linearly independent</em> meaning one can not be written as a multiple (multiplied by a real constant) of the other. Geometrically, this means that the directions corresponding to this two eigenvectors are not on the same line.</p>
<p>In two dimensions, this is enough to say that any given vector <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> can be written as a linear combination of <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span> (or that <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span> consitute a <em>basis</em> of this space). We have:</p>
<div class="math notranslate nohighlight">
\[\mathbf{v}= a_1\mathbf{u_1} + a_2\mathbf{u_2},\]</div>
<p>for constants <span class="math notranslate nohighlight">\(a_1\)</span> and <span class="math notranslate nohighlight">\(a_2\)</span> to be determined.</p>
<p>But given that <span class="math notranslate nohighlight">\(A\)</span> is a linear transformation, it should hold that:</p>
<div class="math notranslate nohighlight">
\[A\mathbf{v} = A(a_1\mathbf{u_1} + a_2\mathbf{u_2}) = a_1A(\mathbf{u_1}) + a_2A(\mathbf{u_2}) = a_1\lambda_1\mathbf{u_1} + a_2\lambda_2\mathbf{u_2},\]</div>
<p>with the last step coming from the fact that <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span> are eigenvectors of <span class="math notranslate nohighlight">\(A\)</span>. Since <span class="math notranslate nohighlight">\(A\mathbf{v}\)</span> is also a vector in this space, we can go ahead and apply the transformation <span class="math notranslate nohighlight">\(A\)</span> again, and we will have:</p>
<div class="math notranslate nohighlight">
\[A(A\mathbf{v}) = A(a_1\lambda_1\mathbf{u_1} + a_2\lambda_2\mathbf{u_2})=a_1\lambda_1 A(\mathbf{u_1}) + a_2\lambda_2 A(\mathbf{u_2}) = a_1\lambda_1^2\mathbf{u_1} + a_2\lambda_2^2\mathbf{u_2}.\]</div>
<p>So, in general:</p>
<div class="math notranslate nohighlight">
\[A(A(A \cdots A\mathbf{v}) \cdots )) = A^n\mathbf{v} = a_1\lambda_1^n\mathbf{u_1} + a_2\lambda_2^n\mathbf{u_2},\]</div>
<p>or, in other words, if we know the eigenvectors and eigenvalues of <span class="math notranslate nohighlight">\(A\)</span> (with <span class="math notranslate nohighlight">\(\lambda_1 \ne \lambda_2\)</span>), and we know the coeffiencients <span class="math notranslate nohighlight">\(a_1\)</span> and <span class="math notranslate nohighlight">\(a_2\)</span> of the expansion of <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> into the eigenvectors, then it is easy to calculate what is going to be the image ov vector <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> by any number of successive applications of <span class="math notranslate nohighlight">\(A\)</span>. This is also equivalent of applying the <span class="math notranslate nohighlight">\(n\)</span>-th power of matrix <span class="math notranslate nohighlight">\(A\)</span> to <span class="math notranslate nohighlight">\(\mathbf{v}\)</span>.</p>
<p>This fact will have many important applications, as we will se next.</p>
</div>
<div class="section" id="structured-models-revisited">
<h2>Structured models revisited<a class="headerlink" href="#structured-models-revisited" title="Permalink to this headline">¶</a></h2>
<p>Let us considered a structured population model defined by the projection matrix <span class="math notranslate nohighlight">\(P=\begin{pmatrix} 1.5 &amp; 2  \\ 0.08 &amp; 0  \end{pmatrix}\)</span> and an initial population vector given by <span class="math notranslate nohighlight">\(\mathbf{n_0} = \begin{pmatrix} 105  \\ 1 \end{pmatrix}\)</span>. If we calculate the eigenvalues and eigenvectors, we will have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\lambda)=\mbox{det}(P-\lambda I) = \mbox{det}\begin{pmatrix} 1.5 -\lambda &amp; 2 \\ 0.08 &amp; -\lambda  \end{pmatrix} = (1.5 -\lambda)(-\lambda) - 0.08\cdot 2 \end{split}\]</div>
<div class="math notranslate nohighlight">
\[p(\lambda)=\lambda^2-1.5\lambda-0.16=(\lambda-1.6)(\lambda+0.1)\]</div>
<p>Thus, we have <span class="math notranslate nohighlight">\(\lambda_1=1.6\)</span> and <span class="math notranslate nohighlight">\(\lambda_2=-0.1\)</span>.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_1 = 1.6}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} 1.5 &amp; 2  \\ 0.08 &amp; 0 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= 1.6\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{1.5x + 2y = 1.6x \\ 0.08x = 1.6y} \longrightarrow \cases{x - 20y = 0 \\ x - 20y = 0}
\end{align}\)</span></p>
<p>Since <span class="math notranslate nohighlight">\(x=20y\)</span>, we choose <span class="math notranslate nohighlight">\(\mathbf{u_1} = \begin{pmatrix} 20  \\ 1  \end{pmatrix}\)</span>.</p>
<br />
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\lambda_2 = -0.1}\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\begin{align}
A\mathbf{v} = \lambda\mathbf{v} \longrightarrow \begin{pmatrix} 1.5 &amp; 2  \\ 0.08 &amp; 0 \end{pmatrix}\begin{pmatrix} x  \\ y \end{pmatrix}= -0.1\begin{pmatrix} x  \\ y \end{pmatrix}\longrightarrow \cases{1.5x + 2y = -0.1x \\ 0.08x = -0.1y} \longrightarrow \cases{0.8x + y = 0 \\ 0.08x + 0.1y = 0}
\end{align}\)</span></p>
<p>Since <span class="math notranslate nohighlight">\(-\displaystyle\frac{4}{5}x=y\)</span>, we choose <span class="math notranslate nohighlight">\(\mathbf{u_2} = \begin{pmatrix} 5  \\ -4  \end{pmatrix}\)</span>.</p>
</li>
</ul>
<br />
<p>We can also note that the initial population vector can be decomposed into the eigenvectors <span class="math notranslate nohighlight">\(\mathbf{u_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{u_2}\)</span> of the matrix <span class="math notranslate nohighlight">\(P\)</span> according to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{n_0}=\begin{pmatrix} 105  \\ 1 \end{pmatrix} = 5\begin{pmatrix} 20  \\ 1 \end{pmatrix} + \begin{pmatrix} 5  \\ -4 \end{pmatrix} = 5\mathbf{u_1} + \mathbf{u_2}\end{split}\]</div>
<p>We know that to find the population vector for the following step, we have to apply the projection matrix on the current population vector. Thus:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{n_1} = P\mathbf{n_0}= P(5\mathbf{u_1} + \mathbf{u_2})=5P(\mathbf{u_1}) + P(\mathbf{u_2})=5(1.6)\begin{pmatrix} 20  \\ 1 \end{pmatrix} + (-0.1)\begin{pmatrix} 5  \\ -4 \end{pmatrix} = \begin{pmatrix} 159.5  \\ 8.4 \end{pmatrix}\end{split}\]</div>
<p>If we perform successive applications of <span class="math notranslate nohighlight">\(P\)</span>, we will finally have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{n_t} = P^t\mathbf{n_0} = P^t(5\mathbf{u_1} + \mathbf{u_2})=5(1.6)^t\begin{pmatrix} 20  \\ 1 \end{pmatrix} + (-0.1)^t\begin{pmatrix} 5  \\ -4 \end{pmatrix}.\end{split}\]</div>
<br />  
<p>By decomposing into eigenvalues and eigenvectors, we know the behaviour of our population for any time <span class="math notranslate nohighlight">\(t\)</span>, which is much easier than applying <span class="math notranslate nohighlight">\(P\)</span> a number <span class="math notranslate nohighlight">\(t\)</span> of times, or than calculating <span class="math notranslate nohighlight">\(P^t\)</span>. Furthermore, as <span class="math notranslate nohighlight">\(t\rightarrow\infty\)</span> the first term will dominate (with the second term dying out) and the proportions for each age class in this population will be dictated by the vector <span class="math notranslate nohighlight">\(\begin{pmatrix} 20  \\ 1 \end{pmatrix}\)</span> (or, if we divide by the sum of the components: <span class="math notranslate nohighlight">\(\displaystyle\frac{1}{21}\begin{pmatrix} 20  \\ 1 \end{pmatrix} = \begin{pmatrix} 95\%  \\ 5\% \end{pmatrix}\)</span>.</p>
<p>In general the eigenvector corresponding to the <strong>largest eigenvalue</strong> (also called <em>dominant eigenvalue</em>) of the projection matrix, which is always <em>real</em> and <em>positive</em>, will correspond to the stable age distribution, for which our population vector converges after we wait enough time.</p>
<p>As we have seen, after enough time, the dominant eigenvalue will also correspond to the growth factor for each of the age classes. Thus, if <span class="math notranslate nohighlight">\(\lambda_1&gt;1\)</span> the population size will increase, whereas if <span class="math notranslate nohighlight">\(0&lt;\lambda_1&lt;1\)</span> the population size will decrease.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture05"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../lecture04/04_From_table_arrangements_to_powerful_tools.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">04 - From table arrangements to powerful tools</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../lecture06/06_Analysing_change_continuously.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">06 - Analysing change, continuously</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Lucas D. Fernandes (adapted by Alexander Kier Christensen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>